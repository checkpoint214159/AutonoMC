{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO:minedojo.tasks] Loaded 1581 Programmatic tasks, 1560 Creative tasks, and 1 special task: \"Playthrough\". Totally 3142 tasks loaded.\n",
      "/mnt/e/AutonoMC/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import minedojo\n",
    "# import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import time\n",
    "import cv2\n",
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "import hashlib\n",
    "import hydra\n",
    "import torch\n",
    "from hydra import compose, initialize\n",
    "from omegaconf import OmegaConf\n",
    "from mineclip import MineCLIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded ckpt\n"
     ]
    }
   ],
   "source": [
    "def main(cfg):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    path = cfg.pop('ckpt_path', None)\n",
    "\n",
    "    # print('cfg', cfg)\n",
    "    # print('device', device)\n",
    "    model = MineCLIP(**cfg).to(device)\n",
    "    model.load_ckpt(path, strict=True)\n",
    "    print(\"Successfully loaded ckpt\")\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "cfg = {\n",
    "    'arch': 'vit_base_p16_fz.v2.t2',\n",
    "    'hidden_dim': 512,\n",
    "    'image_feature_dim': 512,\n",
    "    'mlp_adapter_spec': 'v0-2.t0',\n",
    "    'pool_type': 'attn.d2.nh8.glusw',\n",
    "    'resolution': [160, 256],\n",
    "    'ckpt_path': 'weights/attn.pth'\n",
    "}\n",
    "\n",
    "model = main(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/e/AutonoMC/venv/lib/python3.10/site-packages/numpy/core/numeric.py:330: RuntimeWarning: invalid value encountered in cast\n",
      "  multiarray.copyto(a, fill_value, casting='unsafe')\n",
      "/mnt/e/AutonoMC/venv/lib/python3.10/site-packages/gym/spaces/box.py:73: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  logger.warn(\n",
      "[INFO:minedojo.tasks] Loaded 1581 Programmatic tasks, 1560 Creative tasks, and 1 special task: \"Playthrough\". Totally 3142 tasks loaded.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n"
     ]
    }
   ],
   "source": [
    "frameSize = (160, 256)\n",
    "env = minedojo.make(task_id='harvest_wool_with_shears_and_sheep', image_size=frameSize)\n",
    "out = cv2.VideoWriter('outputs/ahhhh.mp4',cv2.VideoWriter_fourcc(*'mp4v'), 20.0, (frameSize[1], frameSize[0]))\n",
    "prompts = [env.task_prompt]\n",
    "images = []\n",
    "\n",
    "obs = env.reset()\n",
    "for i in range(50):\n",
    "    act = env.action_space.no_op()\n",
    "    act[0] = 1    # forward/backward\n",
    "    if i % 10 == 0:\n",
    "        act[2] = 1    # jump\n",
    "    obs, reward, done, info = env.step(act)\n",
    "    # print('next frame')\n",
    "    # env.render()\n",
    "    \n",
    "    pic = obs['rgb']\n",
    "\n",
    "    pic = pic.transpose((1, 2, 0))\n",
    "    pic = cv2.cvtColor(pic, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    img = pic.transpose((2, 0, 1))\n",
    "    img = img[None, :, :, :]\n",
    "    img = torch.Tensor(img).to('cuda')\n",
    "    images.append(img)\n",
    "\n",
    "    out.write(pic)\n",
    "\n",
    "env.close()\n",
    "out.release()\n",
    "\n",
    "video = torch.stack(images, dim=0)\n",
    "image_feats = model.forward_image_features(video)\n",
    "video_feats = model.forward_video_features(image_feats)\n",
    "video_feats_2 = model.encode_video(video)\n",
    "\n",
    "text_feats_batch = model.encode_text(prompts)\n",
    "\n",
    "VIDEO_BATCH, TEXT_BATCH = video.size(0), len(prompts)\n",
    "\n",
    "assert text_feats_batch.shape == (TEXT_BATCH, 512)\n",
    "\n",
    "# compute reward from features\n",
    "logits_per_video, logits_per_text = model.forward_reward_head(\n",
    "    video_feats, text_tokens=text_feats_batch\n",
    ")\n",
    "assert logits_per_video.shape == (VIDEO_BATCH, TEXT_BATCH)\n",
    "assert logits_per_text.shape == (TEXT_BATCH, VIDEO_BATCH)\n",
    "# directly pass in strings. This invokes the tokenizer under the hood\n",
    "reward_scores_2, _ = model.forward_reward_head(video_feats, text_tokens=prompts)\n",
    "# pass in cached, encoded text features\n",
    "reward_scores_3, _ = model(\n",
    "    video_feats, text_tokens=text_feats_batch, is_video_features=True\n",
    ")\n",
    "reward_scores_4, _ = model(\n",
    "    video, text_tokens=text_feats_batch, is_video_features=False\n",
    ")\n",
    "# all above are equivalent, just starting from features or raw values\n",
    "\n",
    "print(reward_scores_2.shape)\n",
    "print(reward_scores_3.shape)\n",
    "print(reward_scores_4.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Video' from 'IPython' (/mnt/e/AutonoMC/venv/lib/python3.10/site-packages/IPython/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Video\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'Video' from 'IPython' (/mnt/e/AutonoMC/venv/lib/python3.10/site-packages/IPython/__init__.py)"
     ]
    }
   ],
   "source": [
    "from IPython import Video\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1280.0 720.0\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n",
      "(720, 1280, 3) <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture('temp/SampleVideo_1280x720_1mb.mp4')\n",
    "print(cap.get(3), cap.get(4))\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "\n",
    "out = cv2.VideoWriter('outputs/helpme.mp4',fourcc, 20.0,(int(cap.get(3)),int(cap.get(4))))\n",
    "\n",
    "not_done = True\n",
    "while not_done:\n",
    "    not_done, frame = cap.read()\n",
    "    if frame is not None:\n",
    "        print(frame.shape, type(frame))\n",
    "        out.write(frame)\n",
    "\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
